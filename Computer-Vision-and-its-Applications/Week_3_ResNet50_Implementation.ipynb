{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bv68lqztSCox"
      },
      "source": [
        "We will start by setting up a Google Colab environment to work with files stored in Google Drive. First, we mount the Google Drive so that we can access its contents within the Colab notebook."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GE9Pd103SErM",
        "outputId": "03fd9ce5-70c8-433c-ca0e-cfb1fe219d6c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gpvPCNz9UIDx"
      },
      "source": [
        "This code imports necessary libraries and modules for building and training Convolutional Neural Networks (ConvNets) using Keras and TensorFlow. It includes layers for constructing ConvNets, such as convolutional, pooling, activation, and normalization layers. The code also imports utilities for data preprocessing, including loading the CIFAR-100 dataset and preprocessing images. Additionally, it imports ResNet-50, a pre-trained ConvNet model. Overall, this code sets up the environment and tools needed for building and training ConvNets on image classification tasks, leveraging the CIFAR-100 dataset and ResNet-50 architecture."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "oiVZ8VX8RY0p"
      },
      "outputs": [],
      "source": [
        "from keras import layers\n",
        "from keras.layers import (Input, Add, Dense, Activation, ZeroPadding2D, BatchNormalization,\n",
        "                          Flatten, Conv2D, AveragePooling2D, MaxPooling2D, GlobalMaxPooling2D,\n",
        "                          GlobalAveragePooling2D, Dropout, UpSampling2D)\n",
        "from keras.models import Model, load_model, Sequential\n",
        "from keras.initializers import glorot_uniform\n",
        "from keras.datasets import cifar100\n",
        "from keras.applications.resnet50 import preprocess_input\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications.resnet50 import ResNet50"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nzk1TLpxbyrv"
      },
      "source": [
        "# Challenge of Vanishing Gradients in Deep Neural Networks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EhiCgBfBS4Cm"
      },
      "source": [
        "Deep neural networks have the capacity to learn features across various levels of abstraction, ranging from simple features like edges, which are captured in the shallower layers near the input, to highly intricate features found in the deeper layers closer to the output. However, increasing the depth of a network doesn't consistently improve its performance. A significant challenge in training deeper networks is the occurrence of vanishing gradients, where the gradient signal diminishes rapidly during backpropagation, rendering gradient descent impractically slow. Specifically, as you propagate gradients from the final layer back to the initial layer, the multiplication by weight matrices at each step can cause the gradient to diminish exponentially, leading it to approach zero. Consequently, during training, you may observe the gradient magnitude or norm for shallower layers declining rapidly towards zero as the training progresses.\n",
        "\n",
        "Residual Networks (ResNets) employ two primary types of blocks: \"identity blocks\" and \"convolutional blocks\". Identitiy blocks are known as \"shortcuts\" or \"skip connections\", which enable the model to bypass certain layers, as depicted in Figures 1 and 2.\n",
        "\n",
        "![picture](https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ME62WUBfdIcLIWoCHJekhg.jpeg)\n",
        "\n",
        "*Figure 1: ResNets Vs Plain Neural Network taken from [this article](https://towardsdatascience.com/residual-networks-resnets-cb474c7c834a).*\n",
        "\n",
        "![picture](https://theaisummer.com/static/8d19d048cd68d6dce362e025cf3b635a/1ac66/skip-connection.png)\n",
        "\n",
        "*Figure 2: Residual learning: a building block taken from [original ResNet paper](https://openaccess.thecvf.com/content_cvpr_2016/papers/He_Deep_Residual_Learning_CVPR_2016_paper.pdf).*\n",
        "\n",
        "ResNets work by allowing the model to easily learn from previous layers. They do this by adding the original input of a layer to its output, essentially creating a shortcut. This way, the gradient during training can flow smoothly back through the network, helping earlier layers learn better and preventing the vanishing gradients problem. By stacking these shortcut blocks, ResNets can efficiently learn from different parts of the input data. In addition to addressing the issue of vanishing gradients, ResNets are commonly used because they allow later layers to learn from information captured in the initial layers.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d14_R6R6bmlN"
      },
      "source": [
        "# Building a Residual Network (ResNet) Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ueWCPzuddZB2"
      },
      "source": [
        "In ResNets, there are two main types of blocks: the identity block and the convolutional block.\n",
        "\n",
        " - Identity Block: This block is used when the input and output dimensions remain the same. It consists of a series of convolutional layers and other operations, but the shortcut connection (which bypasses these layers) simply adds the input directly to the output. This preserves the dimensionality of the input throughout the block.\n",
        "\n",
        "- Convolutional Block: This block is used when the input and output dimensions do not match up, meaning the convolutional layers inside the block change the dimensions of the input. In contrast to the identity block, the convolutional block incorporates a convolutional layer in the shortcut path. This convolutional layer adjusts the dimensions of the input to match the dimensions of the output so that they can be added together. This ensures that the dimensions align properly for addition and facilitates the flow of information through the network.\n",
        "\n",
        "  ![picture](https://miro.medium.com/v2/resize:fit:1400/format:webp/1*dhQQdqZ_XciBou1yAPL8ow.jpeg)\n",
        "  ![picture](https://miro.medium.com/v2/resize:fit:1400/format:webp/1*NX7Bhwa5yVbA27LRKFLiIQ.jpeg)\n",
        "\n",
        "  *Figure 3: ResNet50 Identity Block (top figure) and Conv Block (bottom figure) taken from this [article](https://towardsdatascience.com/residual-networks-resnets-cb474c7c834a).*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e9cB6stycMgO"
      },
      "source": [
        "## The Identity Block"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JEJuOfb6Zp8e"
      },
      "source": [
        "Here is how the identity_block function is implemented:\n",
        "\n",
        "- It sets up naming conventions for the layers.\n",
        "- Extracts the sizes of filters for each convolution layer.\n",
        "- Saves the input tensor for later addition (shortcut connection).\n",
        "- Builds the main path of the block:\n",
        "  - First, it applies a 1x1 convolution with F1 filters, followed by batch normalization and ReLU activation.\n",
        "  - Then, it applies a convolution with a filter size of filter_size and F2 filters, followed by batch normalization and ReLU activation.\n",
        "  - Finally, it applies another 1x1 convolution with F3 filters, followed by batch normalization.\n",
        "- Adds the shortcut connection to the main path. In specific, after the third convolutional layer, the output is added to the preserved input tensor X_shortcut. This addition operation effectively creates a skip connection that bypasses (or \"skips over\") the three convolutional layers in the main path, allowing the input tensor to directly influence the final output of the block.\n",
        "- Applies ReLU activation to the final output.\n",
        "\n",
        "The function returns the output tensor of the identity block.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "xuueMp4NZqqJ"
      },
      "outputs": [],
      "source": [
        "# FUNCTION: identity_block\n",
        "\n",
        "def identity_block(X, filter_size, num_filters, stage, block):\n",
        "    \"\"\"\n",
        "    This function implements an identity block as shown in Figure 3.\n",
        "\n",
        "    Arguments:\n",
        "    X -- input tensor with shape (m, n_H_prev, n_W_prev, n_C_prev)\n",
        "    filter_size -- integer indicating the size of the middle convolution window in the main path\n",
        "    num_filters -- list of integers specifying the number of filters in the convolution layers of the main path\n",
        "    stage -- integer used for naming layers based on their position in the network\n",
        "    block -- string/character used for naming layers based on their position in the network\n",
        "\n",
        "    Returns:\n",
        "    X -- output tensor of the identity block with shape (n_H, n_W, n_C)\n",
        "    \"\"\"\n",
        "\n",
        "    # Naming conventions setup\n",
        "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
        "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
        "\n",
        "    # Extracting filter sizes\n",
        "    F1, F2, F3 = num_filters\n",
        "\n",
        "    # Preserving the input for later addition to the main path\n",
        "    X_shortcut = X\n",
        "\n",
        "    # Main path's first component\n",
        "    X = Conv2D(F1, 1, padding='valid', name=conv_name_base + '2a')(X)\n",
        "    X = BatchNormalization(axis=3, name=bn_name_base + '2a')(X)\n",
        "    X = Activation('relu')(X)\n",
        "\n",
        "    # Main path's second component\n",
        "    X = Conv2D(F2, filter_size, padding='same', name=conv_name_base + '2b')(X)\n",
        "    X = BatchNormalization(axis=3, name=bn_name_base + '2b')(X)\n",
        "    X = Activation('relu')(X)\n",
        "\n",
        "    # Main path's third component\n",
        "    X = Conv2D(F3, 1, padding='valid', name=conv_name_base + '2c')(X)\n",
        "    X = BatchNormalization(axis=3, name=bn_name_base + '2c')(X)\n",
        "\n",
        "    # Final step: Adding the shortcut to the main path and applying ReLU activation\n",
        "    X = Add()([X, X_shortcut])\n",
        "    X = Activation('relu')(X)\n",
        "\n",
        "    return X"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nS2RtRg1cmBM"
      },
      "source": [
        "## The Convolutional Block"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K5cpAtJ3lZBS"
      },
      "source": [
        "Here is how the convolutional block in ResNet is implemented:\n",
        "\n",
        "- Function Definition: The function convolutional_block takes several arguments including the input tensor X, the filter size, the number of filters, stage number, block identifier, and an optional stride value. It returns the output tensor of the convolutional block.\n",
        "\n",
        "- Naming Conventions: The function sets up naming conventions for the layers based on the stage and block numbers.\n",
        "\n",
        "- Extracting Filter Sizes: The sizes of the filters for each convolutional layer (F1, F2, F3) are extracted from the num_filters argument.\n",
        "\n",
        "- Preserving the Input: The input tensor X is saved as X_shortcut to be used later for the shortcut connection.\n",
        "\n",
        "- Main Path Construction:\n",
        "  - First, a 1x1 convolution is applied with F1 filters and a specified stride (default is 2), followed by batch normalization and ReLU activation.\n",
        "  - Then, a convolution with a filter size specified by filter_size and F2 filters is applied, followed by batch normalization and ReLU activation.\n",
        "  - Finally, another 1x1 convolution is applied with F3 filters, followed by batch normalization.\n",
        "\n",
        "- Shortcut Path Construction: A 1x1 convolution is applied to the preserved input tensor X_shortcut with F3 filters and the same stride as the main path, followed by batch normalization.\n",
        "\n",
        "- Final Step: The output of the main path and the shortcut path are added element-wise. ReLU activation is applied to the summed output.\n",
        "\n",
        "- Return: The final output tensor of the convolutional block is returned.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "0VemCrbalXY3"
      },
      "outputs": [],
      "source": [
        "# FUNCTION: convolutional_block\n",
        "\n",
        "def convolutional_block(X, filter_size, num_filters, stage, block, stride=2):\n",
        "    \"\"\"\n",
        "    This function implements a convolutional block as depicted in Figure 3.\n",
        "\n",
        "    Arguments:\n",
        "    X -- input tensor of shape (m, n_H_prev, n_W_prev, n_C_prev)\n",
        "    filter_size -- integer specifying the size of the middle convolution window in the main path\n",
        "    num_filters -- list of integers defining the number of filters in the convolution layers of the main path\n",
        "    stage -- integer used for layer naming based on its position in the network\n",
        "    block -- string/character used for layer naming based on its position in the network\n",
        "    stride -- integer specifying the stride to be used\n",
        "\n",
        "    Returns:\n",
        "    X -- output tensor of the convolutional block with shape (n_H, n_W, n_C)\n",
        "    \"\"\"\n",
        "\n",
        "    # Setting up naming conventions\n",
        "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
        "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
        "\n",
        "    # Retrieving filter sizes\n",
        "    F1, F2, F3 = num_filters\n",
        "\n",
        "    # Saving the input value\n",
        "    X_shortcut = X\n",
        "\n",
        "    ##### MAIN PATH #####\n",
        "    # First part of the main path\n",
        "    X = Conv2D(F1, 1, strides=(stride, stride), name=conv_name_base + '2a', kernel_initializer='glorot_uniform')(X)\n",
        "    X = BatchNormalization(axis=3, name=bn_name_base + '2a')(X)\n",
        "    X = Activation('relu')(X)\n",
        "\n",
        "    # Second part of the main path\n",
        "    X = Conv2D(F2, filter_size, padding='same', name=conv_name_base + '2b', kernel_initializer='glorot_uniform')(X)\n",
        "    X = BatchNormalization(axis=3, name=bn_name_base + '2b')(X)\n",
        "    X = Activation('relu')(X)\n",
        "\n",
        "    # Third part of the main path\n",
        "    X = Conv2D(F3, 1, name=conv_name_base + '2c', kernel_initializer='glorot_uniform')(X)\n",
        "    X = BatchNormalization(axis=3, name=bn_name_base + '2c')(X)\n",
        "\n",
        "    ##### SHORTCUT PATH ####\n",
        "    X_shortcut = Conv2D(F3, 1, strides=(stride, stride), name=conv_name_base + '1', kernel_initializer='glorot_uniform')(X_shortcut)\n",
        "    X_shortcut = BatchNormalization(axis=3, name=bn_name_base + '1')(X_shortcut)\n",
        "\n",
        "    # Final step: Adding the shortcut value to the main path and applying ReLU activation\n",
        "    X = Add()([X, X_shortcut])\n",
        "    X = Activation('relu')(X)\n",
        "\n",
        "    return X"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JVRdaoOfnY8V"
      },
      "source": [
        "## Building ResNet model with 50 layers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o00keDuYnezz"
      },
      "source": [
        "The ResNet_50 function builds the ResNet-50 architecture by stacking convolutional blocks and identity blocks, incorporating skip connections to facilitate training of very deep networks, and ends with a global average pooling layer and a fully connected output layer for classification.\n",
        "\n",
        "- Function Definition: ResNet_50 function takes two arguments: input_shape, which specifies the shape of the input images, and classes, the number of output classes. It returns a Keras Model instance representing the ResNet-50 model.\n",
        "\n",
        "- Input Tensor: It starts by defining an input tensor X_input with the shape specified by input_shape.\n",
        "\n",
        "- Zero Padding: Zero-padding is applied to the input tensor to make sure the spatial dimensions remain consistent after the initial convolution. Without padding, the image would get smaller as you go deeper into the network. Padding helps prevent information loss at the edges of the image. In addition, it makes sure that every pixel in the image is treated equally by the filters, which helps the network learn better and more meaningful patterns.\n",
        "\n",
        "- Stage 1: The initial convolutional layer (conv1) applies 64 filters of size 7x7 to the input, followed by batch normalization and ReLU activation.\n",
        "Max-pooling is then applied to reduce the spatial dimensions.\n",
        "\n",
        "- Stage 2: It constructs Stage 2, which consists of a convolutional block followed by two identity blocks. The convolutional block applies a convolutional layer followed by batch normalization and ReLU activation, then a shortcut connection is added through the identity blocks.\n",
        "\n",
        "- Stage 3, Stage 4, Stage 5: Similar to Stage 2, but with different numbers of convolutional and identity blocks, each with varying numbers of filters and strides.\n",
        "\n",
        "- Average Pooling: Average pooling with a pool size of 1x1 is applied to reduce the spatial dimensions to 1x1, effectively summarizing the features.\n",
        "\n",
        "- Output Layer: The output of the pooling layer is flattened and fed into a fully connected layer with softmax activation, producing the final output probabilities for each class.\n",
        "\n",
        "- Finally, a Keras Model instance is created with the input and output tensors defined earlier, and the model is named 'ResNet-50'.\n",
        "\n",
        "Here's how the layers are distributed in ResNet-50:\n",
        "\n",
        "- Initial Convolutional Layer (Stage 1): 1 layer\n",
        "- Stage 2:\n",
        "  - 1 Convolutional Block (3 layers)\n",
        "  - 2 Identity Blocks (2 * 3 = 6 layers). *Note that each identity block consists of 3 layers (1 convolutional layer + 1 batch normalization layer + 1 ReLU activation layer).*\n",
        "- Stage 3:\n",
        "  - 1 Convolutional Block (3 layers)\n",
        "  - 3 Identity Blocks (3 * 3 = 9 layers)\n",
        "- Stage 4:\n",
        "  - 1 Convolutional Block (3 layers)\n",
        "  - 5 Identity Blocks (5 * 3 = 15 layers)\n",
        "- Stage 5:\n",
        "  - 1 Convolutional Block (3 layers)\n",
        "  - 2 Identity Blocks (2 * 3 = 6 layers)\n",
        "\n",
        " Adding up all these layers gives us a total of 49 layers.\n",
        "\n",
        "To achieve a total of 50 layers, ResNet-50 also includes fully connected layers (classification layers) at the end, which contribute an additional 1 layer.\n",
        "\n",
        "Below is the architecture of ResNet-50.\n",
        "\n",
        "![picture](https://miro.medium.com/v2/resize:fit:1400/format:webp/0*tH9evuOFqk8F41FG.png)\n",
        "\n",
        "*Figure 4: Resnet-50 Model architecture taken from this [article](https://towardsdatascience.com/the-annotated-resnet-50-a6c536034758)*\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "JkCxs2-FoFgj"
      },
      "outputs": [],
      "source": [
        "def ResNet_50(input_shape=(32, 32, 3), classes=100):\n",
        "    \"\"\"\n",
        "    Implementation of ResNet50 architecture:\n",
        "    CONV2D -> BATCHNORM -> RELU -> MAXPOOL -> CONVBLOCK -> IDBLOCK*2 -> CONVBLOCK -> IDBLOCK*3\n",
        "    -> CONVBLOCK -> IDBLOCK*5 -> CONVBLOCK -> IDBLOCK*2 -> AVGPOOL -> TOPLAYER\n",
        "\n",
        "    Arguments:\n",
        "    input_shape -- shape of the images of the dataset\n",
        "    classes -- integer, number of classes\n",
        "\n",
        "    Returns:\n",
        "    model -- a Model() instance in Keras\n",
        "    \"\"\"\n",
        "\n",
        "    # Input tensor\n",
        "    X_input = Input(input_shape)\n",
        "\n",
        "    # Zero padding\n",
        "    X = ZeroPadding2D((3, 3))(X_input)\n",
        "\n",
        "    # Stage 1\n",
        "    X = Conv2D(64, (7, 7), strides=(2, 2), name='conv1', kernel_initializer=glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis=3, name='bn_conv1')(X)\n",
        "    X = Activation('relu')(X)\n",
        "    X = MaxPooling2D((3, 3), strides=(2, 2))(X)\n",
        "\n",
        "    # Stage 2\n",
        "    X = convolutional_block(X, filter_size=3, num_filters=[64, 64, 256], stage=2, block='a', stride=1)\n",
        "    X = identity_block(X, 3, [64, 64, 256], stage=2, block='b')\n",
        "    X = identity_block(X, 3, [64, 64, 256], stage=2, block='c')\n",
        "\n",
        "    # Stage 3\n",
        "    X = convolutional_block(X, 3, [128, 128, 512], stage=3, block='a', stride=2)\n",
        "    for i in range(3):\n",
        "        X = identity_block(X, 3, [128, 128, 512], stage=3, block=chr(98 + i))\n",
        "\n",
        "    # Stage 4\n",
        "    X = convolutional_block(X, 3, [256, 256, 1024], stage=4, block='a', stride=2)\n",
        "    for i in range(5):\n",
        "        X = identity_block(X, 3, [256, 256, 1024], stage=4, block=chr(98 + i))\n",
        "\n",
        "    # Stage 5\n",
        "    X = convolutional_block(X, 3, [512, 512, 2048], stage=5, block='a', stride=2)\n",
        "    for i in range(2):\n",
        "        X = identity_block(X, 3, [512, 512, 2048], stage=5, block=chr(98 + i))\n",
        "\n",
        "    # Average pooling\n",
        "    X = AveragePooling2D((1, 1), name=\"avg_pool\")(X)\n",
        "\n",
        "    # Output layer\n",
        "    X = Flatten()(X)\n",
        "    X = Dense(classes, activation='softmax', name='fc' + str(classes), kernel_initializer=glorot_uniform(seed=0))(X)\n",
        "\n",
        "    # Create model\n",
        "    model = Model(inputs=X_input, outputs=X, name='ResNet50')\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l2aRTMvDsMYz"
      },
      "source": [
        "Run the following code to build the model's graph."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "CbU7e3bEsMt6"
      },
      "outputs": [],
      "source": [
        "# Creating ResNet50 model\n",
        "model = ResNet_50(input_shape = (32, 32, 3), classes = 100)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uetvZ5WLsl3l"
      },
      "source": [
        "Before training a model, you must set up the learning process by compiling the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "LWJsVrVMsm68"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A4yVdIuwtqqS"
      },
      "source": [
        "The model is prepared for training, and all that's required is a dataset. Now, let's load the CIFAR-100 Dataset. CIFAR-100 is a popular benchmark dataset for image classification tasks, consisting of 60,000 32x32 color images across 100 diverse classes, each containing 500 training and 100 testing images. It serves as a challenging testbed for evaluating machine learning algorithms due to its varied classes, including animals, vehicles, and household items, making it suitable for assessing model generalization and robustness in real-world scenarios.\n",
        "\n",
        "![picture](https://production-media.paperswithcode.com/datasets/CIFAR-100-0000000433-b71f61c0_hPEzMRg.jpg)\n",
        "\n",
        "*Figure 5: A snapshot of the CIFAR100 classes with 10 random images in each  taken from this [source](https://www.cs.toronto.edu/~kriz/cifar.html)*\n",
        "\n",
        "The following code loads the CIFAR-100 dataset. It preprocesses the input images using the preprocess_input function to ensure compatibility with the ResNet-50 model. Additionally, it converts the class labels to one-hot encoded vectors using the to_categorical function, which is essential for categorical classification tasks. Finally, it prints out the number of training and test examples, as well as the shapes of the input and output data arrays, to verify the data preprocessing steps.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n8wNXbJCtrxw",
        "outputId": "721fb4ad-79d7-4d65-b32c-073320500c81"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "number of training examples = 50000\n",
            "number of test examples = 10000\n",
            "X_train shape: (50000, 32, 32, 3)\n",
            "Y_train shape: (50000, 100)\n",
            "X_test shape: (10000, 32, 32, 3)\n",
            "Y_test shape: (10000, 100)\n"
          ]
        }
      ],
      "source": [
        "num_classes = 100\n",
        "\n",
        "(X_train, Y_train), (X_test, Y_test) = cifar100.load_data()\n",
        "\n",
        "#Pre-process the data\n",
        "X_train = preprocess_input(X_train)\n",
        "X_test = preprocess_input(X_test)\n",
        "\n",
        "Y_train = to_categorical(Y_train, num_classes)\n",
        "Y_test = to_categorical(Y_test, num_classes)\n",
        "\n",
        "print (\"number of training examples = \" + str(X_train.shape[0]))\n",
        "print (\"number of test examples = \" + str(X_test.shape[0]))\n",
        "print (\"X_train shape: \" + str(X_train.shape))\n",
        "print (\"Y_train shape: \" + str(Y_train.shape))\n",
        "print (\"X_test shape: \" + str(X_test.shape))\n",
        "print (\"Y_test shape: \" + str(Y_test.shape))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y5iQPC7vxXrY"
      },
      "source": [
        "Execute the code below to train your model for 2 epochs using a batch size of 32.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R8hMbkCzxizi",
        "outputId": "51bfe398-0a37-4852-fbdf-c8430c7a66c9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2\n",
            "1563/1563 [==============================] - 116s 50ms/step - loss: 5.0037 - accuracy: 0.0558\n",
            "Epoch 2/2\n",
            "1563/1563 [==============================] - 72s 46ms/step - loss: 4.1396 - accuracy: 0.1115\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7e5b602688e0>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "model.fit(X_train, Y_train, epochs = 2, batch_size = 32)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kxufked3aTEf"
      },
      "source": [
        "Let's observe the performance of this model, which has been trained for just two epochs, on the test dataset. We can observe that the test accuracy is very low since we only train it for 2 epochs. In the next section, we will leverage transfer learning to enhance the model's performance. By leveraging a pre-trained model, such as ResNet-50 trained on ImageNet, we can initialize our model with learned features and fine-tune it on the CIFAR-100 dataset. This approach often leads to significant improvements in model accuracy and generalization, even with limited training data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xgp2rqBnaU1T",
        "outputId": "6a7c8b9d-8caf-481c-e855-13c89fc7e7d3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 4s 11ms/step - loss: 5.1800 - accuracy: 0.0244\n",
            "Loss = 5.179980278015137\n",
            "Test Accuracy = 0.024399999529123306\n"
          ]
        }
      ],
      "source": [
        "preds = model.evaluate(X_test, Y_test)\n",
        "print (\"Loss = \" + str(preds[0]))\n",
        "print (\"Test Accuracy = \" + str(preds[1]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vMuV-_flR9aQ"
      },
      "source": [
        "# Transfer Learning\n",
        "We will leverage transfer learning with the pre-trained ResNet-50 model to classify images in the CIFAR-100 dataset. The following code fine-tunes the model by adding new layers for classification and freezing the weights of the base model, achieving improved performance on the target task.\n",
        "\n",
        "- Data Preparation: we load the CIFAR-100 dataset and preprocesses the input images using the preprocess_input function to ensure compatibility with the ResNet-50 model.\n",
        "\n",
        "- Data Augmentation: An ImageDataGenerator is defined to perform data augmentation, which includes various transformations like rotation, zooming, and flipping. It is fitted to the training data.\n",
        "\n",
        "- Data Preprocessing: We convert the class labels to one-hot encoded vectors using the to_categorical function. We then resize the input images from CIFAR-100 dataset, which have size 32x32x3, to match the input shape expected by the ResNet-50 model (224x224x3) using the UpSampling2D layer. By upsampling the images by a factor of 7 (since 32 * 7 = 224), the input size is effectively increased to meet the requirements of the ResNet model pretrained on Imagenet dataset.\n",
        "\n",
        "- Model Loading: the pre-trained ResNet-50 model is loaded using the Keras library with specific configurations. By setting include_top=False, the fully connected layers at the top of the network, which are typically tailored for ImageNet classification, are excluded. The weights='imagenet' parameter initializes the model with weights pre-trained on the ImageNet dataset, providing a solid foundation for feature extraction. Additionally, the input shape takes the shape of the resized input images, which is (224x224x3).\n",
        "\n",
        "- Set Trainable Layers: It iterates through all the layers of the ResNet-50 model. If the layer is a batch normalization layer, it sets it to be trainable. Otherwise, it freezes the weights of the other layers by setting trainable=False. This is important because batch normalization relies on statistics calculated during training. Freezing these layers would prevent them from updating their statistics. Therefore, we retrain the batch normalization layer while keeping other layers fixed to ensure reliable predictions.\n",
        "\n",
        "- Model Definition: Defines a Sequential model and adds layers:\n",
        " - Adds the pre-trained ResNet50 model.\n",
        " - Adds a GlobalAveragePooling2D layer to reduce spatial dimensions.\n",
        " - Adds a Dense layer with 256 units and ReLU activation.\n",
        " - Adds a Dropout layer with a dropout rate of 0.25 to prevent overfitting.\n",
        " - Adds a BatchNormalization layer to normalize the activations of the previous layer.\n",
        " - Adds a Dense output layer with softmax activation for multi-class classification.\n",
        "\n",
        " *When you have a binary classification task, such as distinguishing between cats and dogs, you only need two units (neurons) in the output layer instead of 100.*\n",
        "\n",
        "- Model Compilation: The model is compiled with with categorical cross-entropy loss, Adam optimizer, and accuracy metric.\n",
        "\n",
        "- Model Training: The model is trained using the fit_generator function with data augmentation, specifying the batch size, number of training steps per epoch, number of epochs, and validation data.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E8ZQbzgBJeFq",
        "outputId": "68ff403e-5fa8-4f1f-91ba-10568af67a46"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-19-c51800747c84>:53: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  historytemp = model.fit_generator(datagen.flow(x_train, y_train,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "781/781 [==============================] - 442s 543ms/step - loss: 1.9940 - accuracy: 0.4878 - val_loss: 1.0877 - val_accuracy: 0.6796\n",
            "Epoch 2/15\n",
            "781/781 [==============================] - 421s 539ms/step - loss: 1.1596 - accuracy: 0.6634 - val_loss: 0.9364 - val_accuracy: 0.7185\n",
            "Epoch 3/15\n",
            "781/781 [==============================] - 407s 522ms/step - loss: 0.9851 - accuracy: 0.7081 - val_loss: 0.8460 - val_accuracy: 0.7410\n",
            "Epoch 4/15\n",
            "781/781 [==============================] - 407s 522ms/step - loss: 0.8955 - accuracy: 0.7327 - val_loss: 0.7929 - val_accuracy: 0.7554\n",
            "Epoch 5/15\n",
            "781/781 [==============================] - 420s 538ms/step - loss: 0.8256 - accuracy: 0.7506 - val_loss: 0.7910 - val_accuracy: 0.7637\n",
            "Epoch 6/15\n",
            "781/781 [==============================] - 407s 521ms/step - loss: 0.7728 - accuracy: 0.7661 - val_loss: 0.7804 - val_accuracy: 0.7644\n",
            "Epoch 7/15\n",
            "781/781 [==============================] - 420s 538ms/step - loss: 0.7332 - accuracy: 0.7745 - val_loss: 0.7776 - val_accuracy: 0.7700\n",
            "Epoch 8/15\n",
            "781/781 [==============================] - 420s 538ms/step - loss: 0.6896 - accuracy: 0.7862 - val_loss: 0.7660 - val_accuracy: 0.7713\n",
            "Epoch 9/15\n",
            "781/781 [==============================] - 407s 521ms/step - loss: 0.6576 - accuracy: 0.7956 - val_loss: 0.7563 - val_accuracy: 0.7718\n",
            "Epoch 10/15\n",
            "781/781 [==============================] - 420s 538ms/step - loss: 0.6260 - accuracy: 0.8056 - val_loss: 0.7419 - val_accuracy: 0.7810\n",
            "Epoch 11/15\n",
            "781/781 [==============================] - 420s 538ms/step - loss: 0.5977 - accuracy: 0.8126 - val_loss: 0.7478 - val_accuracy: 0.7867\n",
            "Epoch 12/15\n",
            "781/781 [==============================] - 420s 537ms/step - loss: 0.5712 - accuracy: 0.8181 - val_loss: 0.7383 - val_accuracy: 0.7854\n",
            "Epoch 13/15\n",
            "781/781 [==============================] - 420s 537ms/step - loss: 0.5507 - accuracy: 0.8248 - val_loss: 0.7467 - val_accuracy: 0.7853\n",
            "Epoch 14/15\n",
            "781/781 [==============================] - 420s 537ms/step - loss: 0.5304 - accuracy: 0.8309 - val_loss: 0.7328 - val_accuracy: 0.7909\n",
            "Epoch 15/15\n",
            "781/781 [==============================] - 406s 520ms/step - loss: 0.5149 - accuracy: 0.8358 - val_loss: 0.7555 - val_accuracy: 0.7857\n"
          ]
        }
      ],
      "source": [
        "num_classes = 100\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = cifar100.load_data()\n",
        "\n",
        "#Pre-process the data\n",
        "x_train = preprocess_input(x_train)\n",
        "x_test = preprocess_input(x_test)\n",
        "\n",
        "# Define an ImageDataGenerator for data augmentation\n",
        "datagen = ImageDataGenerator(\n",
        "    rotation_range=10,\n",
        "    zoom_range=0.1,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    shear_range=0.1,\n",
        "    horizontal_flip=True,\n",
        "    vertical_flip=False\n",
        ")\n",
        "\n",
        "# Fit the ImageDataGenerator to the training data\n",
        "datagen.fit(x_train)\n",
        "\n",
        "y_train = to_categorical(y_train, num_classes)\n",
        "y_test = to_categorical(y_test, num_classes)\n",
        "\n",
        "# Input layer to resize input images to (224, 224)\n",
        "input_layer = Input(shape=(32, 32, 3))\n",
        "resized_input = UpSampling2D(size=(7, 7))(input_layer)\n",
        "\n",
        "# Load ResNet50 model with pre-trained weights and modified input shape\n",
        "resnet_model = ResNet50(weights='imagenet', include_top=False, input_tensor=resized_input)\n",
        "\n",
        "# Freeze layers in the pre-trained ResNet50 model\n",
        "for layer in resnet_model.layers:\n",
        "    if isinstance(layer, BatchNormalization):\n",
        "        layer.trainable = True\n",
        "    else:\n",
        "        layer.trainable = False\n",
        "\n",
        "# Define a Sequential model and add layers\n",
        "model = Sequential()\n",
        "model.add(resnet_model)\n",
        "model.add(GlobalAveragePooling2D())\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(Dropout(.25))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
        "\n",
        "# Train the model with data augmentation\n",
        "historytemp = model.fit_generator(datagen.flow(x_train, y_train,\n",
        "                                  batch_size=64),\n",
        "                                  steps_per_epoch=x_train.shape[0] // 64,\n",
        "                                  epochs=15,\n",
        "                                  validation_data=(x_test, y_test))\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model Evaluation: The model is evaluated on the test data and the test loss and accuracy are printed. Note that the model can be further improved by increasing the number of epochs."
      ],
      "metadata": {
        "id": "R0TkRCcsr699"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "1LqL0SmulekF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b9493ae0-8c6a-4b24-a9ec-f029091de704"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test loss: 0.7555370330810547\n",
            "Test accuracy: 0.7857000231742859\n"
          ]
        }
      ],
      "source": [
        "# Evaluate the model\n",
        "score = model.evaluate(x_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TG6nnQYVXate"
      },
      "source": [
        "The following code demonstrates how to use the pre-trained model to make predictions on an image of your choice. It loads the image, preprocesses it to match the model's input size and format, and then uses the trained model to predict the class probabilities for each of the 100 classes. Finally, it prints the top 5 predicted class labels of the test image."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "OVxbSuIWW5da",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6671e0a5-49ea-415d-be90-f8e9d4ec4346"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 22ms/step\n",
            "Top 5 predicted classes:\n",
            "leopard\n",
            "tiger\n",
            "hamster\n",
            "wolf\n",
            "fox\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.preprocessing import image\n",
        "\n",
        "# Load CIFAR-100 class labels\n",
        "cifar100_labels = [\n",
        "    'apple', 'aquarium_fish', 'baby', 'bear', 'beaver', 'bed', 'bee', 'beetle',\n",
        "    'bicycle', 'bottle', 'bowl', 'boy', 'bridge', 'bus', 'butterfly', 'camel',\n",
        "    'can', 'castle', 'caterpillar', 'cattle', 'chair', 'chimpanzee', 'clock',\n",
        "    'cloud', 'cockroach', 'couch', 'crab', 'crocodile', 'cup', 'dinosaur',\n",
        "    'dolphin', 'elephant', 'flatfish', 'forest', 'fox', 'girl', 'hamster',\n",
        "    'house', 'kangaroo', 'computer_keyboard', 'lamp', 'lawn_mower', 'leopard',\n",
        "    'lion', 'lizard', 'lobster', 'man', 'maple_tree', 'motorcycle', 'mountain',\n",
        "    'mouse', 'mushroom', 'oak_tree', 'orange', 'orchid', 'otter', 'palm_tree',\n",
        "    'pear', 'pickup_truck', 'pine_tree', 'plain', 'plate', 'poppy', 'porcupine',\n",
        "    'possum', 'rabbit', 'raccoon', 'ray', 'road', 'rocket', 'rose', 'sea',\n",
        "    'seal', 'shark', 'shrew', 'skunk', 'skyscraper', 'snail', 'snake', 'spider',\n",
        "    'squirrel', 'streetcar', 'sunflower', 'sweet_pepper', 'table', 'tank',\n",
        "    'telephone', 'television', 'tiger', 'tractor', 'train', 'trout', 'tulip',\n",
        "    'turtle', 'wardrobe', 'whale', 'willow_tree', 'wolf', 'woman', 'worm'\n",
        "]\n",
        "\n",
        "# Load an example image\n",
        "img_path = '/content/yourimage.jpg'\n",
        "img = image.load_img(img_path, target_size=(32, 32))  # Resize the image to match the input size of the model\n",
        "img_array = image.img_to_array(img)  # Convert image to numpy array\n",
        "img_array = np.expand_dims(img_array, axis=0)  # Add a batch dimension\n",
        "\n",
        "# Preprocess the image (normalize pixel values)\n",
        "img_array = preprocess_input(img_array)\n",
        "\n",
        "# Make predictions\n",
        "predictions = model.predict(img_array)\n",
        "\n",
        "# Get the top 5 predicted class indices\n",
        "top_indices = np.argsort(predictions[0])[-5:][::-1]\n",
        "\n",
        "# Convert indices to class labels\n",
        "top_labels = [cifar100_labels[idx] for idx in top_indices]\n",
        "\n",
        "# Print the top 5 predicted class labels\n",
        "print(\"Top 5 predicted classes:\")\n",
        "for label in top_labels:\n",
        "    print(label)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}